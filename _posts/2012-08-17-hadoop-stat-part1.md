---
layout: default
published: true
---

# Hadoop统计平台（一）

不知不觉大半年都一直在负责统计，不过还包括统计自动化系统的设计，而不但只是跑跑脚本，虽然这种事情也得经常做。  

长时间下来在这个统计系统的设计、开发和维护等方面都有不少感想，不过忙碌的工作让我也没时间把这些都整理下来，最近终于有这个机会了。这是一个线下的统计系统，依赖于前段服务器产生的日志信息进行各种流量统计。目前这个系统可以在一个小时内完成每日大量的统计计算，而目前每日的日志量大概是70G。  

下面是一幅简单的示意图，表示统计系统是如何获取线上日志数据的：  
![获取日志结构](/assets/get_log_flow.png)  

目前使用的下载方式是scp，*这样的架构需要维护掌握的前段服务器名字，因此这里过去曾经出现过几次因为前段机器已经上线了，但没有通知我，于是新增机器的日志就没有被下载，如果延误超过一天，那么就会出现数据统计错误*。所以这里应该形成机制，只要有新的服务器上线，就应该通知到维护统计系统的人。  

目前在HDFS中采用2备份的存储方式，连3备份都用不上，因为集群机器只有6台，也就是说只有5台是用来存储数据的。  

接下来就是统计任务执行过程的数据流图：
![计算任务数据流](/assets/compute_data_flow.png)
